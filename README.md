# Doubt Tutor ğŸ¤”

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B.svg)](https://streamlit.io)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Groq](https://img.shields.io/badge/Powered%20by-Groq-orange.svg)](https://groq.com)
[![Hugging Face](https://img.shields.io/badge/HuggingFace-ğŸ¤—-yellow.svg)](https://huggingface.co)


An innovative AI-driven educational platform that provides instant, personalized academic support through cutting-edge language models. Built with Streamlit and powered by Groq's lightning-fast AI infrastructure.

## âœ¨ Features

- **ğŸ¤– Multi-Model AI Support**: Choose from multiple specialized AI models
  - LLaMA 3.1 (8B) - Fast, efficient text responses
  - Mistral 7B - Balanced creative and analytical tasks
  - DeepSeek R1 - Advanced reasoning for complex problems
  - Qwen2-VL Vision - Image and diagram understanding

- **ğŸ“ Multi-Format File Support**: Upload and analyze PDFs, images, and text files
- **ğŸ’¬ Real-time Chat Interface**: Clean, modern UI with markdown and code highlighting
- **ğŸ¨ Professional Design**: Dark/light theme with smooth animations
- **ğŸ’¾ Export Conversations**: Save your learning sessions as JSON
- **ğŸ”’ Privacy First**: No data stored without consent
- **âš¡ Lightning Fast**: Powered by Groq's optimized inference engine

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9 or higher
- Anaconda/Miniconda (recommended)
- Groq API key ([Get one here](https://console.groq.com))
- HuggingFace API token ([Get one here](https://huggingface.co/settings/tokens))

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/doubt-tutor.git
   cd doubt-tutor
   ```

2. **Create and activate conda environment**
   ```bash
   conda create -n edu python=3.9
   conda activate edu
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   ```bash
   # Copy example config
   cp config/.env.example .env
   
   # Edit .env and add your API keys
   # On Windows: notepad .env
   # On Mac/Linux: nano .env
   ```
   
   Add your API keys to `.env`:
   ```env
   GROQ_API_KEY=your_groq_api_key_here
   HF_TOKEN=your_huggingface_token_here
   ```

5. **Run the application**
   ```bash
   streamlit run ui/app.py
   ```

The app will open in your browser at `http://localhost:8501`

## ğŸ“ Project Structure

```
doubt-tutor/
â”œâ”€â”€ config/                 # Configuration files
â”‚   â”œâ”€â”€ .env.example       # Environment variables template
â”‚   â”œâ”€â”€ auth_config.yaml   # Authentication settings
â”‚   â”œâ”€â”€ config.yaml        # App configuration
â”‚   â””â”€â”€ models_config.yaml # Model parameters
â”œâ”€â”€ src/                   # Core application logic
â”‚   â”œâ”€â”€ core/             # Core functionality
â”‚   â”‚   â”œâ”€â”€ config.py     # Configuration management
â”‚   â”‚   â”œâ”€â”€ constants.py  # App constants
â”‚   â”‚   â””â”€â”€ exceptions.py # Custom exceptions
â”‚   â”œâ”€â”€ models/           # AI model integrations
â”‚   â”‚   â””â”€â”€ ai_manager.py # Model orchestration
â”‚   â”œâ”€â”€ utils/            # Helper utilities
â”‚   â”‚   â”œâ”€â”€ decorators.py # Custom decorators
â”‚   â”‚   â”œâ”€â”€ helpers.py    # Helper functions
â”‚   â”‚   â””â”€â”€ logger.py     # Logging setup
â”‚   â””â”€â”€ load_env.py       # Environment loader
â”œâ”€â”€ ui/                    # Frontend components
â”‚   â”œâ”€â”€ app.py            # Main Streamlit app
â”‚   â”œâ”€â”€ components/       # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ chat_interface.py
â”‚   â”‚   â””â”€â”€ header.py
â”‚   â”œâ”€â”€ pages/            # Multi-page navigation
â”‚   â”‚   â”œâ”€â”€ 1_About.py
â”‚   â”‚   â”œâ”€â”€ 2_How_It_Works.py
â”‚   â”‚   â””â”€â”€ 3_Models.py
â”‚   â””â”€â”€ styles/           # CSS and animations
â”‚       â”œâ”€â”€ style.css
â”‚       â””â”€â”€ animations.js
â”œâ”€â”€ data/                 # Data storage
â”‚   â”œâ”€â”€ uploads/         # User uploaded files
â”‚   â”œâ”€â”€ exports/         # Exported conversations
â”‚   â””â”€â”€ processed/       # Processed data
â”œâ”€â”€ logs/                # Application logs
â”œâ”€â”€ docs/                # Documentation
â”‚   â”œâ”€â”€ API.md
â”‚   â”œâ”€â”€ CHANGELOG.md
â”‚   â”œâ”€â”€ CONTRIBUTING.md
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ SETUP.md
â”œâ”€â”€ .dockerignore        # Docker ignore rules
â”œâ”€â”€ .gitignore          # Git ignore rules
â”œâ”€â”€ Dockerfile          # Docker configuration
â”œâ”€â”€ LICENSE             # MIT License
â”œâ”€â”€ README.md           # This file
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ setup.py           # Package setup
```

## ğŸ¯ Usage

### Basic Workflow

1. **Select Your Model**: Choose the AI model that best fits your needs from the Models page
2. **Ask Your Question**: Type your question in the chat interface
3. **Upload Files** (optional): Attach PDFs, images, or text files for context
4. **Get Instant Response**: Receive detailed, step-by-step explanations
5. **Export History**: Save your conversation for future reference

### Model Selection Guide

| Model | Best For | Speed | Capabilities |
|-------|----------|-------|--------------|
| **LLaMA 3.1 (8B)** | Quick answers, math, science | âš¡âš¡âš¡ | Text only |
| **Mistral 7B** | Creative writing, essays | âš¡âš¡ | Text only |
| **DeepSeek R1** | Complex reasoning, coding | âš¡ | Text + Code |
| **Qwen2-VL Vision** | Images, diagrams, charts | âš¡âš¡ | Text + Vision |

### Example Use Cases

**For Math Problems:**
```
Question: Explain how to solve quadratic equations
Model: LLaMA 3.1 or DeepSeek R1
```

**For Essay Writing:**
```
Question: Help me structure an essay about climate change
Model: Mistral 7B
```

**For Diagram Analysis:**
```
Question: [Upload image] Explain this diagram
Model: Qwen2-VL Vision
```

**For Code Debugging:**
```
Question: Why isn't this Python code working? [paste code]
Model: DeepSeek R1
```

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file in the root directory:

```env
# Required API Keys
GROQ_API_KEY=your_groq_api_key_here
HF_TOKEN=your_huggingface_token_here

# Optional Settings
LOG_LEVEL=INFO
MAX_FILE_SIZE_MB=10
ENABLE_ANALYTICS=false
DEBUG_MODE=false
```

### Model Configuration

Edit `config/models_config.yaml` to customize model parameters:

```yaml
models:
  llama-3.1-8b-instant:
    provider: groq
    temperature: 0.7
    max_tokens: 2048
    
  mistral:
    provider: groq
    temperature: 0.8
    max_tokens: 4096
    
  deepseek-r1:
    provider: groq
    temperature: 0.7
    max_tokens: 4096
    
  hf-vision:
    provider: huggingface
    temperature: 0.7
    max_tokens: 2048
```

## ğŸ³ Docker Deployment

Build and run with Docker:

```bash
# Build image
docker build -t doubt-tutor .

# Run container
docker run -p 8501:8501 \
  -e GROQ_API_KEY=your_key \
  -e HF_TOKEN=your_token \
  doubt-tutor
```

Or use Docker Compose:

```bash
docker-compose up -d
```

## ğŸ› ï¸ Development

### Setup Development Environment

```bash
# Install development dependencies
pip install -r requirements.txt

# Install pre-commit hooks (optional)
pip install pre-commit
pre-commit install

# Run tests (if available)
pytest tests/
```

### Code Style

This project follows PEP 8 guidelines with:
- Black for code formatting
- Flake8 for linting
- isort for import sorting

```bash
# Format code
black src/ ui/

# Check linting
flake8 src/ ui/

# Sort imports
isort src/ ui/
```

### Running Locally

```bash
# Activate environment
conda activate edu

# Run app
streamlit run ui/app.py

# Run with custom port
streamlit run ui/app.py --server.port 8080

# Run in development mode
streamlit run ui/app.py --server.runOnSave true
```

## ğŸ“Š Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Streamlit UI Layer          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   App    â”‚  Pages   â”‚ Componentsâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Application Layer             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ AI Manager   â”‚  File Handler   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  Groq API   â”‚      â”‚  HF API     â”‚
â”‚  (Text)     â”‚      â”‚  (Vision)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](docs/CONTRIBUTING.md) for guidelines.

### How to Contribute

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Development Guidelines

- Write clear, descriptive commit messages
- Add tests for new features
- Update documentation as needed
- Follow the existing code style
- Ensure all tests pass before submitting PR

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Groq** - For providing lightning-fast AI inference
- **HuggingFace** - For vision model hosting
- **Streamlit** - For the amazing web framework
- **Meta AI** - For LLaMA models
- **Mistral AI** - For Mistral models
- **DeepSeek** - For reasoning models
- **Alibaba Cloud** - For Qwen2-VL vision model

## ğŸ“ Support

- ğŸ“§ Email: support@doubttutor.com
- ğŸ’¬ Discord: [Join our community](https://discord.gg/doubttutor)
- ğŸ› Issues: [GitHub Issues](https://github.com/yourusername/doubt-tutor/issues)
- ğŸ“– Docs: [Full Documentation](docs/README.md)

## ğŸ—ºï¸ Roadmap

### Completed âœ…
- [x] Multi-model support
- [x] File upload capabilities (PDF, images, text)
- [x] Dark/light theme
- [x] Export conversations
- [x] Professional UI/UX
- [x] Code syntax highlighting
- [x] Responsive design

### In Progress ğŸš§
- [ ] User authentication system
- [ ] Conversation history persistence
- [ ] Advanced analytics dashboard

### Planned ğŸ“‹
- [ ] Mobile app (iOS/Android)
- [ ] Voice input/output
- [ ] Collaborative learning sessions
- [ ] Integration with learning management systems
- [ ] API for third-party integrations
- [ ] Offline mode
- [ ] Multi-language support

## âš ï¸ Disclaimer

This is an educational tool designed to assist with learning. Always verify critical information from authoritative sources. The AI models may occasionally produce incorrect or biased information.

**Important Notes:**
- Not a replacement for professional tutoring or formal education
- Responses should be verified for accuracy
- Use responsibly and ethically
- Follow your institution's academic integrity policies

## ğŸ”’ Security

- API keys are never logged or stored
- Files are temporarily processed and not permanently stored
- All communications are encrypted
- No user data is collected without consent

To report security vulnerabilities, please email security@doubttutor.com

## ğŸ“ˆ System Requirements

### Minimum Requirements
- Python 3.9+
- 4 GB RAM
- 2 GB free disk space
- Modern web browser (Chrome, Firefox, Safari, Edge)

### Recommended Requirements
- Python 3.10+
- 8 GB RAM
- 5 GB free disk space
- High-speed internet connection

## ğŸŒ Browser Support

| Browser | Supported | Version |
|---------|-----------|---------|
| Chrome | âœ… | Latest |
| Firefox | âœ… | Latest |
| Safari | âœ… | 14+ |
| Edge | âœ… | Latest |
| Opera | âœ… | Latest |

## ğŸ“Š Performance

- Average response time: < 2 seconds
- Concurrent users supported: 100+
- File upload limit: 10 MB
- Maximum conversation length: Unlimited

## ğŸ”„ Updates

This project is actively maintained. Check the [CHANGELOG.md](docs/CHANGELOG.md) for version history and updates.

## ğŸ“š Additional Resources

- [Setup Guide](docs/SETUP.md) - Detailed installation instructions
- [API Documentation](docs/API.md) - For developers
- [Contributing Guide](docs/CONTRIBUTING.md) - How to contribute
- [FAQ](docs/README.md) - Frequently asked questions

---

<div align="center">
  <strong>Built with â¤ï¸ by the Doubt Tutor Team</strong>
  <br>
  <sub>Empowering learners worldwide through AI â€¢ Founded 2025</sub>
  <br><br>
  <a href="#quick-start">Get Started</a> â€¢
  <a href="#features">Features</a> â€¢
  <a href="docs/README.md">Documentation</a> â€¢
  <a href="#support">Support</a>
</div>